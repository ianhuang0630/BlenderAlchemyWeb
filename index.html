
<!DOCTYPE html>
<html>

<head lang="en">
    
    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-XFDR35RQ52"></script>
    <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-XFDR35RQ52');
    </script>
    

    <meta charset="UTF-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">


    <meta name="description"
        content="BlenderAlchemy: Editing 3D Graphics with Vision-Language Models">
    <meta name="keywords" content="3D Graphics, AI agent, LLM">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>BlenderAlchemy</title>

    
    <!--FACEBOOK-->
    <meta property="og:image" content="img/social.png">
    <meta property="og:image:type" content="image/png">
    <meta property="og:image:width" content="1280">
    <meta property="og:image:height" content="720">
    <meta property="og:type" content="website" />
    <meta property="og:url" content="ianhuang0630.github.io/BlenderAlchemyWeb/" />
    <meta property="og:title" content="BlenderAlchemy" />
    <meta property="og:description"
        content="Project page for BlenderAlchemy" />

    <!--TWITTER-->
    <meta name="twitter:card" content="summary_large_image" />
    <meta name="twitter:title" content="BlenderAlchemy" />
    <meta name="twitter:description"
        content="Project page for BlenderAlchemy" />
    <meta name="twitter:image" content="img/social.png" />


    <!--     <link rel="apple-touch-icon" href="apple-touch-icon.png"> -->
    <!-- <link rel="icon"
        href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üêà</text></svg>"> -->
    <link rel="icon" type="image/png" href="img/favicon.png">
    <!-- Place favicon.ico in the root directory -->

    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/css/bootstrap.min.css">
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.1/css/all.min.css">
    <link rel="stylesheet" href="css/app.css">

    <link rel="stylesheet" href="css/bootstrap.min.css">

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/js/bootstrap.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/1.5.3/clipboard.min.js"></script>

    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script type="text/javascript" id="MathJax-script" async
    src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js">
    </script>

    <link rel="stylesheet" href="css/dics.min.css">
    <!-- <script src="scripts/dics.min.js"></script> -->
    <script>
        document.addEventListener('DOMContentLoaded', domReady);
        function domReady() {
            for (const e of document.querySelectorAll(".b-dics")) {
                new Dics({
                    container: e,
                    textPosition: "top"
                });
            }
        }
    </script>
</head>




<body>
    
    <div class="banner multiple-color-gradient">
        <div class="banner-title">
            <h2 class="col-md-12 text-center title">
                <!-- <b>CAD</b><img src ="img/icon.png" style="width: 3%; height: 3%; position: relative; top: -3px"> </br>‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã -->
                <img src ="img/logo.png" style="width: 30px; height: 30px; position: relative; top: -3px">
                <!-- <img src ="img/logo.png" style="width: 8vw; height: auto; position: relative; top: -3px"></br> -->
                <b>BlenderAlchemy</b></br> 
                Editing 3D Graphics with Vision-Language Models</br>
                <!-- <small>arXiv</small> -->
            </h2>
            <div class="col-md-12 text-center">
                <div style="margin-bottom: 0.7em; margin-top:0.2em" class="authors">
                    <a  class="authors_link" href="https://ianhuang0630.github.io/">Ian Huang</a>&nbsp;&nbsp;&nbsp;&nbsp;
                    <a  class="authors_link" href="https://www.guandaoyang.com/">Guandao Yang</a>&nbsp;&nbsp;&nbsp;&nbsp;
                    <a  class="authors_link" href="https://geometry.stanford.edu/member/guibas/">Leonidas Guibas</a>
                </div>

                <div style="margin-bottom: 0.5em;" class="affiliations">
                    Stanford University
                </div>

                <!-- <div style="margin-bottom: 0.7em;" class="col-md-12 text-center">
                    *denotes equal contribution
                </div> -->

            </div>
            <div class=" text-center button_row">
              <!-- Second button -->
                <div class="nav nav-justified button_content">
                    <div class="button_item">
                        <a href="https://arxiv.org/abs/2404.17672" class="button">
                          <!-- <i class="fas fa-paperclip"></i>  -->
                          <i class="fa-solid fa-paperclip"></i> 
                          Paper
                        </a>
                    </div>
                    <div class="button_item">
                        <a href="https://github.com/ianhuang0630/BlenderAlchemyOfficial" class="button">
                          <!-- <i class="fas fa-code"></i>  -->
                          <i class="fa-brands fa-github"></i>
                          Code
                        </a>                     
                    </div>
                    <div class="button_item">
                        <a href="https://github.com/ianhuang0630/BlenderAlchemyPlugin" class="button">
                          <!-- <i class="fas fa-magic"></i>  -->
                          <i class="fa-solid fa-wand-magic-sparkles"></i>
                          Blender Plugin
                        </a>
                        <!-- TODO REMOVE THIS ONCE LINKED -->
                        <div class="coming-soon">
                            Coming soon!
                        </div>
                      </div>
                  </div>
            </div>
        </div>
        <div class="banner-visual" id="banner-instance-container">
            <!-- TODO : replace with animation -->
            <!-- <img src="img/options_front.png" class="banner-img"> -->
        </div> 
    </div>

    
    <div class="container" id="main">
        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Abstract
                </h3>
                <!-- <image src="img/rays.jpg" class="img-responsive" alt="overview"><br> -->
                <p class="text-justify">
			Graphics design is important for various applications, including movie production and game design. To create a high-quality scene, designers usually need to spend hours in software like Blender, in which they might need to interleave and repeat operations, such as connecting material nodes, hundreds of times. Moreover, slightly different design goals may require completely different sequences, making automation difficult. In this paper, we propose a system that leverages Vision-Language Models (VLMs), like GPT-4V, to intelligently search the design action space to arrive at an answer that can satisfy a user's intent. Specifically, we design a vision-based edit generator and state evaluator to work together to find the correct sequence of actions to achieve the goal. Inspired by the role of visual imagination in the human design process, we supplement the visual reasoning capabilities of VLMs with "imagined" reference images from image-generation models, providing visual grounding of abstract language descriptions. In this paper, we provide empirical evidence suggesting our system can produce simple but tedious Blender editing sequences for tasks such as editing procedural materials and geometry from text and/or reference images, as well as adjusting lighting configurations for product renderings in complex scenes.
                </p>
                <br>
                
            </div>
        </div>

        
        <!-- Materials -->
        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Editing 3D Graphics as Visual Program Refinement
                </h3> 


                <div id="pipeline-instance-container">
                    <!-- javascript-injected content -->
                </div>
                
                <p class="text-justify">
                    To perform edits within the Blender 3D design environment, BlenderAlchemy iteratively  refines a program that defines a sequence of edits within Blender. This is done using our visual program refinement procedure, which is composed of an edit generator <b>G</b> and a state evaluator <b>V</b>, which iteratively generates and selects among different edit hypotheses, respectively. Both the edit generator and the state evaluator are guided by an input user intention, specified using a combination of language and reference images, either provided or hallucinated using an text-to-image generator within the Visual Imagination module. At each step, we allow for the system to revert back to the edit hypothesis from a previous iteration.
                </p>

                <div id="editing-instance-container">
                    <!-- javascript-injected content -->
                </div>
                    
                <p class="text-justify">
                    In the context of the material editing task, consider the task of transforming a wooden procedural material into marbled granite. The following is an illustrative sample of a sequence of edit generation and state selection steps.
                </p>


                <div id="marbleprocess-instance-container">
                    <!-- javascript-injected content -->
                </div>

                <h3>
                    Materials
                </h3>
                <!-- <h4>
                    Real Captured Scenes
                </h4> -->
                <p class="text-justify">
                    Using this system, we can edit procedural materials using language descriptions. We show a few samples below,
                    edited based on the wooden material on the left.
                </p>

                <div id="wood2others-instance-container">
                     <!-- javascript-injected content -->
                </div>
                
                <p class="text-justify">
                    Below, we show the application of a set of materials synthesized by BlenderAlchemy
                    on a diverse set of scenes based off of assets created by 3D artists. BlenderAlchemy
                    is capable of producing usable materials guided by language descriptions and also
                    generating variations of the same kind of material.
                </p>

                <div id="cartunnel-instance-container">
                    <!-- javascript-injected content -->
                </div>
                

                <div id="katanas-instance-container">
                    <!-- javascript-injected content -->
                </div>
                
                <!-- Nike Video -->
                <div class="video-sample">
                    <div class="video-container">
                        <div class="video-container-element">
                            Old metal (Original)
                        </div>
                        <div class="video-container-element">
                            Ice slats
                        </div>
                        <div class="video-container-element">
                            Surface of the sun
                        </div>
                    </div>

                    
                    <div class="video-container" id="shoe-instance-container">
                        <!-- javascript-injected content -->
                    </div>
                </div>

        
                <p class="text-justify">
                    The code edits synthesized by BlenderAlchemy represent changes to the procedural 
                    material graph of the input procedural material, ranging in changes in continuous values, 
                    node connectivity, and node types. Take the following example of editing 
                    a procedural wood material (top) into marbled granite (bottom), using the 
                    language description shown below:
                </p>
                
                <div id="graph-instance-container">
                    <div class="image-sample">
                        <image src="img/nodegraphs.png" style="width:100%;" class="img-responsive center-block" alt="node graph"></image>  
                    </div>
                </div>
                

                
            </div>
        </div>
    
         <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Geometry 
                </h3>
                <!-- <h4>
                    Real Captured Scenes
                </h4> -->
                <p class="text-justify">
                    Certain geometry edits can be expressed in code as well, and are therefore amenable 
                    to edits from BlenderAlchemy. For procedural geometry, we can convert geometry nodes 
                    into a python script using a similar process as the one for materials. In the following
                    example, BlenderAlchemy edits a subset of 60 geometry nodes to make the roses "bloom".
                </p>
                
                <div id="rosebloom-instance-container">
                    <!-- javascript-injected content -->
                    <!-- <div class="video-sample">
                        <video src="videos/roses_blooming.mp4"  autoplay loop muted >
                        </video>
                    </div> -->
                </div>

                <p class="text-justify">
                    Blend shapes can also be expressed as a python program, which assigns coefficients to
                    different blend shapes. In the example below, BlenderAlchemy edits the 
                    blend coefficients to create different facial expressions to match the emotion 
                    behind hypothetical script lines, using 19 facial blend shapes. 
                </p>
                 
                <div id="faceanim-instance-container">
                    <!-- <div class="video-sample">
                        <video src="videos/face_anim.mp4" autoplay loop muted>
                        </video>
                    </div> -->
                </div>
                
            </div>
        </div>

        
        <!-- Lighting -->
        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Lighting
                </h3>
                <!-- <h4>
                    Real Captured Scenes
                </h4> -->
                <p class="text-justify">
                    Since BlenderAlchemy works by editing programs, BlenderAlchemy can also change lighting configurations within scenes,
                    since the parameters of each lighting source can be programmatically represented.
                    Using the same method as for material editing, we can iteratively synthesize lighting setups that match a certain
                    language description by cycling between automatically generating candidates of lighting candidates and 
                    selecting among them.
                </p>
                <div class="image-sample">
                    <image src="img/hand_lotion.png" style="width:80%;" class="img-responsive center-block" alt="overview"></image>
                </div>

                <p class="text-justify">
                    Employing BlenderAlchemy iteratively between optimizing lighting and materials allow a user 
                    to tweak both in the input scene to satisfy their desired intention.
                </p>
                <div class="image-sample">
                    <image src="img/comet_cream.png" style="width:80%;" class="img-responsive center-block" alt="overview"></image>
                </div>
            </div>
        </div>

        <!-- 
        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Geometry Nodes
                </h3>
            </div>
        </div>
        -->
        
        <!-- 
        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Acknowledgements
                </h3>
                <p class="text-justify">
                    I. Huang and L. Guibas acknowledge the support of ARL grant (W911NF21-2-0104), a Vannevar Bush Faculty Fellowship, and gifts from the Adobe and Snap Corporations. And special thanks to Fred Again.. 
                </p>
            </div>
        </div> -->

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Citation
                </h3>
                <div class="form-group col-md-10 col-md-offset-1">
                    <p> If you found the paper or code useful, please cite:
                    </p>
                    <textarea id="bibtex" class="form-control" readonly>
@misc{huang2024blenderalchemy,
    title={BlenderAlchemy: Editing 3D Graphics with Vision-Language Models}, 
    author={Ian Huang and Guandao Yang and Leonidas Guibas},
    year={2024},
    eprint={2404.17672},
    archivePrefix={arXiv},
    primaryClass={cs.CV}
}
                    </textarea>
                </div>
            </div>
        </div>

        <div class="website-footer">
            <a href="https://ianhuang0630.github.io/">
                <img src ="img/personal_logo_gray.png" style="width: 30px; height: 30px; position: relative;" alt="Who made this?" onmouseover="this.src='img/personal_logo_purple.png';" onmouseout="this.src='img/personal_logo_gray.png';"> 
            </a>
        </div>
        
        <script>
            var isPhone = /Android|webOS|iPhone|iPad|iPod|BlackBerry|IEMobile|Opera Mini/i.test(navigator.userAgent);
            console.log("is Phone:", isPhone) ;
            
            // Banner
            const banner_img = '<img src="img/options_front.png" class="banner-img">';
            const banner_video = '<video class="banner-video" src="videos/Banner.mp4" height="100%" autoplay loop muted >'
                + '</video>'; 

            // Pipeline overview
            const pipeline_example_img  = '<div class="image-sample">'
                + '<image src="img/blenderalchemy_pipeline.png" style="width:100%;" class="img-responsive center-block" alt="pipeline"></image>'
                + '</div>';
            const pipeline_example_vids = '<div class="video-sample">'
                + '<video src="videos/MethodsOverview.mp4" width="50px" autoplay muted >'
                + '</video>'
                + '</div>';
                    
            // Program Editing
            const editing_example_img = '<div class="image-sample">'
                        + '<image src="img/methods_overview.png" style="width:100%;" class="img-responsive center-block" alt="overview"></image>'
                        + '</div>';
            const editing_example_vids = '<div class="video-sample">'
                    + '<video src="videos/ProgramEdits.mp4" width="50px" autoplay muted >'
                    + '</video>'
                    + '</div>';

            // Marble process
            const marbleprocess_example_gifs = '<div class="video-sample">'
                +'<image src="gifs/marble_process.gif" style="width:100%;" class="img-responsive center-block" alt="marble process"></image>'
                + '</div>'
            const marbleprocess_example_vids = '<div class="video-sample">'
                + '<video src="videos/marble_process_animation.mp4" width="50px" autoplay loop muted controls>'
                + '</video>'
                + '</div>'


            // Wood2Others
            const wood2others_example_gifs = '<div class="video-sample">'
                    + '<image src="gifs/Wood2others_animation.gif" style="width:100%;" class="img-responsive center-block" alt="wood to others"></image>'
                    + '</div>';
            const wood2others_example_vids = '<div class="video-sample">'
                + '<video src="videos/Wood2others_animation.mp4" width="50px" autoplay loop muted>'
                +'</video>'
                '</div>';
            
            // Car tunnel
            const cartunnel_example_gifs = '<div class="video-sample">'
                    + '<image src="gifs/car_tunnel.gif" style="width:100%;" class="img-responsive center-block" alt="car in tunnel"></image>'
                    + '</div>';
            const cartunnel_example_vids = ' <div class="video-sample">'
                        + '<video src="videos/car_tunnel.mp4" width="50px" autoplay loop muted  controls>'
                        + '</video>'
                        + '</div>';
                        
            // Katanas
            const katanas_example_gifs = '<div class="video-sample">'
                    + '<image src="gifs/katanas_animation.gif" style="width:100%;" class="img-responsive center-block" alt="katanas"></image>'
                    + '</div>';
            const katanas_example_vids = '<div class="video-sample">'
                    + '<video src="videos/katanas_animation.mp4" width="50px" autoplay loop muted>'
                    + '</video>'
                    + '</div>';


            // Shoes
            const shoe_example_gifs = '<div class="video-container-element">'
                        + '<image src="gifs/nike_metal_0000-0100.gif" style="width:100%;" class="img-responsive center-block" alt="old metal"></image>'
                        + '</div>'
                        + ' <div class="video-container-element">'
                        + '<image src="gifs/nike_ice_0000-0100.gif" style="width:100%;" class="img-responsive center-block" alt="ice slats"></image>'
                        + '</div>'
                        + '<div class="video-container-element">'
                        + '<image src="gifs/nike_sun_0000-0100.gif" style="width:100%;" class="img-responsive center-block" alt="surface of the sun"></image>'
                        + '</div>';

            const shoe_example_vids = '<div class="video-container-element">'
                            + '<video src="videos/nike_metal_0000-0100.mp4" autoplay loop muted>'
                            + '</video>'
                            + '</div>'
                            + '<div class="video-container-element">'
                            + '<video src="videos/nike_ice_0000-0100.mp4" autoplay loop muted>'
                            + '</video>'
                            + '</div>'
                            + '<div class="video-container-element">'
                            + '<video src="videos/nike_sun_0000-0100.mp4" autoplay loop muted>'
                            + '</video>'
                            + '</div>';
            
            // roses
            const rose_example_gifs = '<div class="video-sample">'
                        + '<image src="gifs/roses_blooming.gif" style="width:100%;" class="img-responsive center-block" alt="roses blooming"></image>'
                        + '</div>';
            const rose_example_vids = '<div class="video-sample">'
                    + '<video src="videos/roses_blooming.mp4" width="50px" autoplay loop muted>'
                    + '</video>'
                    + '</div>';

            // face
            const faceanim_example_gifs = '<div class="video-sample">'
                        + '<image src="gifs/face_anim.gif" style="width:100%;" class="img-responsive center-block" alt="facial expressions with blender shape keys"></image>'
                        + '</div>';
            const faceanim_example_vids = '<div class="video-sample">'
                    + '<video src="videos/face_anim.mp4" width="50px" autoplay loop muted>'
                    + '</video>'
                    + '</div>';


            var banner_mediaElement = isPhone ? banner_img : banner_video;
            var pipeline_mediaElement = isPhone ? pipeline_example_img: pipeline_example_vids;
            var editing_mediaElement = isPhone ? editing_example_img : editing_example_vids;
            var marbleprocess_mediaElement = isPhone ? marbleprocess_example_gifs : marbleprocess_example_vids;
            var wood2others_mediaElement = isPhone ? wood2others_example_gifs: wood2others_example_vids;               
            var cartunnel_mediaElement = isPhone ? cartunnel_example_gifs: cartunnel_example_vids;               
            var katanas_mediaElement = isPhone ? katanas_example_gifs: katanas_example_vids;
            var shoe_mediaElement = isPhone ? shoe_example_gifs : shoe_example_vids;

            var rose_mediaElement = isPhone ? rose_example_gifs : rose_example_vids;
            var faceanim_mediaElement = isPhone ? faceanim_example_gifs: faceanim_example_vids;

            document.getElementById('banner-instance-container').innerHTML = banner_mediaElement;
            document.getElementById('pipeline-instance-container').innerHTML = pipeline_mediaElement;
            document.getElementById('editing-instance-container').innerHTML = editing_mediaElement;
            document.getElementById('marbleprocess-instance-container').innerHTML = marbleprocess_mediaElement;
            document.getElementById('wood2others-instance-container').innerHTML = wood2others_mediaElement;
            document.getElementById('cartunnel-instance-container').innerHTML = cartunnel_mediaElement;
            document.getElementById('katanas-instance-container').innerHTML = katanas_mediaElement;
            document.getElementById('shoe-instance-container').innerHTML = shoe_mediaElement;
                        
            document.getElementById('rosebloom-instance-container').innerHTML = rose_mediaElement;
            document.getElementById('faceanim-instance-container').innerHTML = faceanim_mediaElement;
            
        </script>
</body>



</html>
